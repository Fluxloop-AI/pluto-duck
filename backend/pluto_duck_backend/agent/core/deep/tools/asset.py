"""Asset tools for the deep agent.

These tools allow the agent to:
1. Save analyses as reusable assets
2. Run saved analyses
3. Query freshness and lineage
4. List and search assets (analyses and file assets)
"""

from __future__ import annotations

import logging
from pathlib import Path
from typing import Any, Dict, List, Literal, Optional

import duckdb
from langchain_core.tools import StructuredTool

from pluto_duck_backend.app.core.config import get_settings
from pluto_duck_backend.app.services.asset import (
    AssetService,
    get_asset_service,
    AssetNotFoundError,
    FileAssetService,
    get_file_asset_service,
    FilePreprocessingService,
    get_file_preprocessing_service,
    DiagnosisIssueService,
    get_diagnosis_issue_service,
)
from pluto_duck_backend.app.services.asset.errors import AssetValidationError

logger = logging.getLogger("pluto_duck_backend.agent.tools.asset")


def build_asset_tools(*, warehouse_path: Path, project_id: Optional[str] = None) -> List[StructuredTool]:
    """Build asset tools bound to a specific warehouse and project.
    
    Args:
        warehouse_path: Path to the DuckDB warehouse
        project_id: Project ID for asset isolation
    """
    print(f"[build_asset_tools] project_id={project_id}", flush=True)

    def _get_connection() -> duckdb.DuckDBPyConnection:
        return duckdb.connect(str(warehouse_path))

    # =========================================================================
    # Save / Create Analysis
    # =========================================================================

    def save_analysis(
        sql: str,
        name: str,
        description: Optional[str] = None,
        materialization: Literal["view", "table", "append", "parquet"] = "view",
        tags: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """Save the current analysis as a reusable Asset in the Asset Library.

        âš ï¸ IMPORTANT: This is the ONLY way to create views/tables that appear in the Asset Library.
        Do NOT use run_sql("CREATE VIEW ...") - those won't be tracked or visible to the user.

        Saved analyses can be:
        - Executed later with `run_analysis`
        - Referenced in Board dashboards
        - Tracked for freshness and lineage

        Args:
            sql: The SQL query to save
            name: Human-readable name (e.g., "ì›”ë³„ ë§¤ì¶œ ë¶„ì„")
            description: Optional description of what this analysis does
            materialization: How to store results:
                - "view": Virtual view (computed on-demand)
                - "table": Physical table (faster queries)
                - "append": Add new rows to existing table
                - "parquet": Export to Parquet file
            tags: Optional tags for organization (e.g., ["sales", "monthly"])

        Returns:
            Status and saved analysis details

        Example:
            save_analysis(
                sql="SELECT month, SUM(amount) FROM orders GROUP BY 1",
                name="ì›”ë³„ ë§¤ì¶œ",
                materialization="table",
                tags=["sales", "reporting"]
            )
        """
        print(f"[save_analysis] Called with name={name}, project_id={project_id}", flush=True)
        service = get_asset_service(project_id)
        print(f"[save_analysis] AssetService project_id={service.project_id}", flush=True)

        try:
            analysis = service.create_analysis(
                sql=sql,
                name=name,
                description=description,
                materialization=materialization,
                tags=tags,
            )
            print(f"[save_analysis] Created analysis id={analysis.id}, project_id={service.project_id}", flush=True)

            return {
                "status": "success",
                "message": f"âœ… '{name}' Assetì´ ì €ì¥ë˜ì—ˆì–´ìš”. (ID: {analysis.id})",
                "analysis_id": analysis.id,
                "name": analysis.name,
                "materialization": analysis.materialize,
                "result_table": analysis.result_table,
                "hint": f"run_analysis('{analysis.id}')ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ Registryì—ì„œ ê´€ë¦¬í•  ìˆ˜ ìˆì–´ìš”.",
            }
        except AssetValidationError as e:
            print(f"[save_analysis] Validation error: {e}", flush=True)
            return {
                "status": "error",
                "message": f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}",
            }

    # =========================================================================
    # Run Analysis
    # =========================================================================

    def run_analysis(
        analysis_id: str,
        params: Optional[Dict[str, Any]] = None,
        force: bool = False,
    ) -> Dict[str, Any]:
        """Run a saved analysis.

        Args:
            analysis_id: ID of the analysis to run
            params: Parameter values if the analysis has parameters
            force: If True, run even if the result is still fresh

        Returns:
            Execution result with status and details

        Example:
            run_analysis("monthly_sales")
            run_analysis("cohort_analysis", params={"start_date": "2024-01-01"})
        """
        service = get_asset_service(project_id)

        with _get_connection() as conn:
            try:
                # Check freshness first
                if not force:
                    freshness = service.get_freshness(analysis_id, conn)
                    if not freshness.is_stale:
                        return {
                            "status": "skipped",
                            "message": f"â„¹ï¸ '{analysis_id}'ëŠ” ì´ë¯¸ ìµœì‹  ìƒíƒœì˜ˆìš”.",
                            "analysis_id": analysis_id,
                            "last_run_at": freshness.last_run_at.isoformat() if freshness.last_run_at else None,
                            "hint": "ê°•ì œë¡œ ì‹¤í–‰í•˜ë ¤ë©´ force=Trueë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
                        }

                # Run the analysis
                result = service.run_analysis(analysis_id, conn, params=params, force=force)

                if result.success:
                    # Get last step result for summary
                    last_step = result.step_results[-1] if result.step_results else None

                    return {
                        "status": "success",
                        "message": f"âœ… '{analysis_id}' ì‹¤í–‰ ì™„ë£Œ!",
                        "analysis_id": analysis_id,
                        "steps_executed": len([s for s in result.step_results if s.status == "success"]),
                        "rows_affected": last_step.rows_affected if last_step else None,
                        "duration_ms": last_step.duration_ms if last_step else None,
                    }
                else:
                    # Find the failed step
                    failed_step = next((s for s in result.step_results if s.status == "failed"), None)

                    return {
                        "status": "error",
                        "message": f"âŒ '{analysis_id}' ì‹¤í–‰ ì‹¤íŒ¨",
                        "analysis_id": analysis_id,
                        "error": failed_step.error if failed_step else "Unknown error",
                    }

            except AssetNotFoundError:
                return {
                    "status": "error",
                    "message": f"âŒ '{analysis_id}' Assetì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.",
                    "hint": "list_analyses()ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ Asset ëª©ë¡ì„ í™•ì¸í•´ë³´ì„¸ìš”.",
                }

    # =========================================================================
    # List Analyses
    # =========================================================================

    def list_analyses(
        tags: Optional[List[str]] = None,
        show_freshness: bool = False,
    ) -> Dict[str, Any]:
        """List all saved analyses.

        Args:
            tags: Filter by tags (e.g., ["sales", "reporting"])
            show_freshness: Include freshness status for each analysis

        Returns:
            List of analyses with details
        """
        service = get_asset_service(project_id)
        analyses = service.list_analyses(tags)

        if not analyses:
            return {
                "status": "success",
                "message": "ì €ì¥ëœ Analysisê°€ ì—†ì–´ìš”.",
                "analyses": [],
            }

        result_list = []
        conn = None

        if show_freshness:
            conn = _get_connection()

        try:
            for a in analyses:
                item = {
                    "id": a.id,
                    "name": a.name,
                    "materialization": a.materialize,
                    "tags": a.tags or [],
                    "result_table": a.result_table,
                }

                if show_freshness and conn:
                    try:
                        freshness = service.get_freshness(a.id, conn)
                        item["is_stale"] = freshness.is_stale
                        item["last_run_at"] = freshness.last_run_at.isoformat() if freshness.last_run_at else None
                    except Exception:
                        item["is_stale"] = None

                result_list.append(item)
        finally:
            if conn:
                conn.close()

        return {
            "status": "success",
            "count": len(result_list),
            "analyses": result_list,
        }

    # =========================================================================
    # Get Analysis Details
    # =========================================================================

    def get_analysis(analysis_id: str) -> Dict[str, Any]:
        """Get details of a specific analysis.

        Args:
            analysis_id: ID of the analysis

        Returns:
            Analysis details including SQL, parameters, tags
        """
        service = get_asset_service(project_id)
        analysis = service.get_analysis(analysis_id)

        if not analysis:
            return {
                "status": "error",
                "message": f"âŒ '{analysis_id}' Assetì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.",
            }

        return {
            "status": "success",
            "id": analysis.id,
            "name": analysis.name,
            "sql": analysis.sql,
            "description": analysis.description,
            "materialization": analysis.materialize,
            "parameters": [
                {
                    "name": p.name,
                    "type": p.type,
                    "required": p.required,
                    "default": p.default,
                }
                for p in (analysis.parameters or [])
            ],
            "tags": analysis.tags or [],
            "result_table": analysis.result_table,
            "created_at": analysis.created_at.isoformat() if analysis.created_at else None,
            "updated_at": analysis.updated_at.isoformat() if analysis.updated_at else None,
        }

    # =========================================================================
    # Get Lineage
    # =========================================================================

    def get_lineage(analysis_id: str) -> Dict[str, Any]:
        """Get data lineage for an analysis.

        Shows what data sources the analysis depends on (upstream)
        and what other analyses depend on it (downstream).

        Args:
            analysis_id: ID of the analysis

        Returns:
            Lineage information with upstream and downstream dependencies
        """
        service = get_asset_service(project_id)

        try:
            lineage = service.get_lineage(analysis_id)

            return {
                "status": "success",
                "analysis_id": analysis_id,
                "upstream": lineage.upstream,
                "downstream": lineage.downstream,
            }
        except AssetNotFoundError:
            return {
                "status": "error",
                "message": f"âŒ '{analysis_id}' Assetì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.",
            }

    # =========================================================================
    # Get Freshness
    # =========================================================================

    def get_freshness(analysis_id: str) -> Dict[str, Any]:
        """Check if an analysis needs to be re-run.

        Args:
            analysis_id: ID of the analysis

        Returns:
            Freshness status with is_stale flag and details
        """
        service = get_asset_service(project_id)

        with _get_connection() as conn:
            try:
                freshness = service.get_freshness(analysis_id, conn)

                status_emoji = "ğŸŸ¢" if not freshness.is_stale else "ğŸŸ¡"

                return {
                    "status": "success",
                    "analysis_id": analysis_id,
                    "is_stale": freshness.is_stale,
                    "display": f"{status_emoji} {'Stale' if freshness.is_stale else 'Fresh'}",
                    "last_run_at": freshness.last_run_at.isoformat() if freshness.last_run_at else None,
                    "stale_reason": freshness.stale_reason,
                }
            except AssetNotFoundError:
                return {
                    "status": "error",
                    "message": f"âŒ '{analysis_id}' Assetì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.",
                }

    # =========================================================================
    # Delete Analysis
    # =========================================================================

    def delete_analysis(analysis_id: str) -> Dict[str, Any]:
        """Delete a saved analysis.

        Args:
            analysis_id: ID of the analysis to delete

        Returns:
            Status message
        """
        service = get_asset_service(project_id)

        if service.delete_analysis(analysis_id):
            return {
                "status": "success",
                "message": f"âœ… '{analysis_id}' Assetì„ ì‚­ì œí–ˆì–´ìš”.",
            }

        return {
            "status": "error",
            "message": f"âŒ '{analysis_id}' Assetì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.",
        }

    # =========================================================================
    # List File Assets (CSV/Parquet)
    # =========================================================================

    def list_files() -> Dict[str, Any]:
        """List all imported file assets (CSV/Parquet).

        File assets are imported via the UI and stored as DuckDB tables.
        Use this to discover what file data is available for analysis.

        Returns:
            List of file assets with table names and metadata

        Example:
            files = list_files()
            # Returns: {"files": [{"name": "ê³ ê° ë°ì´í„°", "table_name": "customers", ...}]}
            # Then query: run_sql("SELECT * FROM customers")
        """
        file_service = get_file_asset_service(project_id)
        files = file_service.list_files()

        if not files:
            return {
                "status": "success",
                "message": "ì„í¬íŠ¸ëœ íŒŒì¼ì´ ì—†ì–´ìš”.",
                "files": [],
            }

        file_list = [
            {
                "id": f.id,
                "name": f.name,
                "table_name": f.table_name,
                "file_type": f.file_type,
                "row_count": f.row_count,
                "column_count": f.column_count,
                "description": f.description,
                "created_at": f.created_at.isoformat() if f.created_at else None,
            }
            for f in files
        ]

        return {
            "status": "success",
            "count": len(file_list),
            "files": file_list,
            "hint": "run_sql('SELECT * FROM {table_name}')ë¡œ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆì–´ìš”.",
        }

    # =========================================================================
    # Dataset Readiness (Preprocessing)
    # =========================================================================

    def get_readiness_summary() -> Dict[str, Any]:
        """Summarize preprocessing readiness for all file assets.

        Returns:
            Total datasets, ready count, not-ready count, and details for non-ready files.
        """
        file_service: FileAssetService = get_file_asset_service(project_id)
        preprocessing_service: FilePreprocessingService = get_file_preprocessing_service(project_id)
        assets = file_service.list_files()

        total = len(assets)
        ready_count = 0
        not_ready: List[Dict[str, Any]] = []

        for asset in assets:
            effective = preprocessing_service.get_effective_status(
                file_asset_id=asset.id,
                current_diagnosis_id=asset.diagnosis_id,
            )
            if effective.status == "ready":
                ready_count += 1
                continue

            name = asset.name or asset.table_name or asset.file_path or asset.id
            not_ready.append(
                {
                    "file_asset_id": asset.id,
                    "name": name,
                    "status": effective.status,
                    "stale": effective.stale,
                    "reason": effective.reason,
                    "last_diagnosis_id": effective.last_diagnosis_id,
                }
            )

        return {
            "status": "success",
            "total": total,
            "ready_count": ready_count,
            "not_ready_count": total - ready_count,
            "not_ready": not_ready,
        }

    def list_not_ready(include_unknown: bool = True) -> Dict[str, Any]:
        """List file assets that are not ready for analysis.

        Args:
            include_unknown: If True, include 'unknown' statuses; otherwise only 'not_ready'.
        """
        file_service: FileAssetService = get_file_asset_service(project_id)
        preprocessing_service: FilePreprocessingService = get_file_preprocessing_service(project_id)
        assets = file_service.list_files()

        not_ready: List[Dict[str, Any]] = []
        for asset in assets:
            effective = preprocessing_service.get_effective_status(
                file_asset_id=asset.id,
                current_diagnosis_id=asset.diagnosis_id,
            )
            if effective.status == "ready":
                continue
            if effective.status == "unknown" and not include_unknown:
                continue

            name = asset.name or asset.table_name or asset.file_path or asset.id
            not_ready.append(
                {
                    "file_asset_id": asset.id,
                    "name": name,
                    "status": effective.status,
                    "stale": effective.stale,
                    "reason": effective.reason,
                    "last_diagnosis_id": effective.last_diagnosis_id,
                }
            )

        return {
            "status": "success",
            "count": len(not_ready),
            "not_ready": not_ready,
        }

    def set_readiness_status(
        file_asset_id: str,
        status: Literal["unknown", "not_ready", "ready"],
        reason: Optional[str] = None,
        actor: Optional[str] = None,
        last_diagnosis_id: Optional[str] = None,
        event_type: Optional[str] = None,
        event_message: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Update preprocessing readiness status for a file asset.

        Args:
            file_asset_id: File asset ID
            status: new status (unknown|not_ready|ready)
            reason: optional explanation
            actor: who updated the status
            last_diagnosis_id: attach to current diagnosis if omitted
            event_type: optional event type to log
            event_message: optional event message to log
        """
        file_service: FileAssetService = get_file_asset_service(project_id)
        preprocessing_service: FilePreprocessingService = get_file_preprocessing_service(project_id)

        if last_diagnosis_id is None:
            asset = file_service.get_file(file_asset_id)
            last_diagnosis_id = asset.diagnosis_id if asset else None

        status_obj = preprocessing_service.set_status(
            file_asset_id=file_asset_id,
            status=status,
            reason=reason,
            actor=actor,
            last_diagnosis_id=last_diagnosis_id,
        )

        event = None
        if event_type:
            event = preprocessing_service.append_event(
                file_asset_id=file_asset_id,
                event_type=event_type,
                message=event_message,
                actor=actor,
            )

        return {
            "status": "success",
            "readiness": status_obj.to_dict(),
            "event": event.to_dict() if event else None,
        }

    def append_preprocessing_event(
        file_asset_id: str,
        event_type: str,
        message: Optional[str] = None,
        actor: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Append a preprocessing event for a file asset."""
        preprocessing_service: FilePreprocessingService = get_file_preprocessing_service(project_id)
        event = preprocessing_service.append_event(
            file_asset_id=file_asset_id,
            event_type=event_type,
            message=message,
            actor=actor,
        )
        return {
            "status": "success",
            "event": event.to_dict(),
        }

    # =========================================================================
    # Diagnosis Issues
    # =========================================================================

    def list_diagnosis_issues(
        file_asset_id: str,
        status: Optional[str] = None,
        include_deleted: bool = False,
    ) -> Dict[str, Any]:
        """List diagnosis issues for a file asset."""
        issue_service: DiagnosisIssueService = get_diagnosis_issue_service(project_id)
        issues = issue_service.list_issues(
            file_asset_id=file_asset_id,
            include_deleted=include_deleted,
            status=status,
        )
        return {
            "status": "success",
            "count": len(issues),
            "issues": [issue.to_dict() for issue in issues],
        }

    def set_issue_status(
        issue_id: str,
        status: Optional[str] = None,
        user_response: Optional[str] = None,
        resolved_by: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Update a diagnosis issue status/user_response."""
        issue_service: DiagnosisIssueService = get_diagnosis_issue_service(project_id)
        updated = issue_service.update_issue(
            issue_id=issue_id,
            status=status,
            user_response=user_response,
            resolved_by=resolved_by,
        )
        if not updated:
            return {
                "status": "error",
                "message": "Issue not found.",
            }
        return {
            "status": "success",
            "issue": updated.to_dict(),
        }

    # =========================================================================
    # Build Tool List
    # =========================================================================

    return [
        StructuredTool.from_function(
            name="save_analysis",
            func=save_analysis,
            description=(
                "í˜„ì¬ ë¶„ì„ì„ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ Assetìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. "
                "ì €ì¥ëœ Assetì€ ë‚˜ì¤‘ì— ì‹¤í–‰í•˜ê±°ë‚˜ Boardì— ì¶”ê°€í•  ìˆ˜ ìˆì–´ìš”."
            ),
        ),
        StructuredTool.from_function(
            name="run_analysis",
            func=run_analysis,
            description=(
                "ì €ì¥ëœ Analysisë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. "
                "ì´ë¯¸ ìµœì‹  ìƒíƒœë©´ ê±´ë„ˆë›°ê³ , force=Trueë¡œ ê°•ì œ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ìš”."
            ),
        ),
        StructuredTool.from_function(
            name="list_analyses",
            func=list_analyses,
            description="ì €ì¥ëœ Analysis ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. íƒœê·¸ë¡œ í•„í„°ë§í•  ìˆ˜ ìˆì–´ìš”.",
        ),
        StructuredTool.from_function(
            name="get_analysis",
            func=get_analysis,
            description="íŠ¹ì • Analysisì˜ ìƒì„¸ ì •ë³´ (SQL, íŒŒë¼ë¯¸í„°, íƒœê·¸ ë“±)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
        ),
        StructuredTool.from_function(
            name="get_lineage",
            func=get_lineage,
            description=(
                "Analysisì˜ ë°ì´í„° ê³„ë³´(Lineage)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. "
                "ì–´ë–¤ ë°ì´í„°ì— ì˜ì¡´í•˜ê³  ì–´ë–¤ ë¶„ì„ì— ì˜í–¥ì„ ì£¼ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”."
            ),
        ),
        StructuredTool.from_function(
            name="get_freshness",
            func=get_freshness,
            description="Analysisê°€ ìµœì‹  ìƒíƒœì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤. Staleì´ë©´ ì¬ì‹¤í–‰ì´ í•„ìš”í•´ìš”.",
        ),
        StructuredTool.from_function(
            name="delete_analysis",
            func=delete_analysis,
            description="ì €ì¥ëœ Analysisë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.",
        ),
        # File Asset tools
        StructuredTool.from_function(
            name="list_files",
            func=list_files,
            description=(
                "ì„í¬íŠ¸ëœ íŒŒì¼(CSV/Parquet) ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. "
                "íŒŒì¼ì´ ì–´ë–¤ í…Œì´ë¸”ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  run_sqlë¡œ ì¿¼ë¦¬í•  ìˆ˜ ìˆì–´ìš”."
            ),
        ),
        # Readiness tools
        StructuredTool.from_function(
            name="get_readiness_summary",
            func=get_readiness_summary,
            description="íŒŒì¼ ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ ì¤€ë¹„ ìƒíƒœ ìš”ì•½ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
        ),
        StructuredTool.from_function(
            name="list_not_ready",
            func=list_not_ready,
            description="ë¶„ì„ ì¤€ë¹„ê°€ ë˜ì§€ ì•Šì€ íŒŒì¼ ë°ì´í„°ì…‹ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
        ),
        StructuredTool.from_function(
            name="set_readiness_status",
            func=set_readiness_status,
            description="íŒŒì¼ ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ ì¤€ë¹„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.",
        ),
        StructuredTool.from_function(
            name="append_preprocessing_event",
            func=append_preprocessing_event,
            description="ì „ì²˜ë¦¬ ê´€ë ¨ ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.",
        ),
        # Diagnosis issue tools
        StructuredTool.from_function(
            name="list_diagnosis_issues",
            func=list_diagnosis_issues,
            description="íŒŒì¼ ì§„ë‹¨ ì´ìŠˆ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
        ),
        StructuredTool.from_function(
            name="set_issue_status",
            func=set_issue_status,
            description="ì§„ë‹¨ ì´ìŠˆ ìƒíƒœ/ì‘ë‹µì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.",
        ),
    ]
